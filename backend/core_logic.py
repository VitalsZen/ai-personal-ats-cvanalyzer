# backend/core_logic.py
import os
import time
from dotenv import load_dotenv
from typing import List, Dict, Union

# --- Imports ---
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_chroma import Chroma

from langchain_huggingface import HuggingFaceEmbeddings 
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnablePassthrough
from pydantic import BaseModel, Field

load_dotenv()

# --- DATA MODELS ---
class JobMatchResult(BaseModel):
    personal_info: Dict[str, str] = Field(description="Name, position, experience extracted from CV")
    matching_score: Dict[str, Union[int, str]] = Field(description="Percentage score and explanation")
    requirements_breakdown: Dict[str, str] = Field(description="Ratios for must-have and nice-to-have criteria")
    matched_keywords: List[str] = Field(description="List of matching technical skills")
    radar_chart: Dict[str, int] = Field(description="Scores 1-10 for 5 dimensions")
    # [NEW] Th√™m tr∆∞·ªùng l√Ω do ch·∫•m ƒëi·ªÉm
    radar_reasoning: Dict[str, Dict[str, str]] = Field(description="Reasoning in en and vi. Structure: {'Hard Skills': {'en': '...', 'vi': '...'}}")
    bilingual_content: Dict[str, Union[Dict, List]] = Field(description="Assessment content in EN and VI")

CORE_PROMPT = """
B·∫°n l√† m·ªôt Tr·ª£ l√Ω Tuy·ªÉn d·ª•ng AI chuy√™n nghi·ªáp (JobMatchr). Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch CV (ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi d·∫°ng text) v√† M√¥ t·∫£ c√¥ng vi·ªác (JD - m·ªói d√≤ng l√† m·ªôt y√™u c·∫ßu).

**INPUT DATA:**
1. CV Text: {cv_text}
2. JD Text: {jd_text} (L∆∞u √Ω: M·ªói d√≤ng trong JD l√† m·ªôt ti√™u ch√≠ ri√™ng bi·ªát).

**NHI·ªÜM V·ª§:**
H√£y th·ª±c hi·ªán c√°c b∆∞·ªõc sau m·ªôt c√°ch logic:

B∆Ø·ªöC 1: TR√çCH XU·∫§T TH√îNG TIN C√Å NH√ÇN
- T√¨m Name, Position (V·ªã tr√≠ ·ª©ng tuy·ªÉn/hi·ªán t·∫°i), Experience (T·ªïng s·ªë nƒÉm kinh nghi·ªám - ch·ªâ l·∫•y s·ªë).

B∆Ø·ªöC 2: PH√ÇN T√çCH JD V√Ä T√çNH ƒêI·ªÇM (QUY T·∫ÆC "1 ƒê·ªÄU")
- T√°ch JD th√†nh c√°c d√≤ng ri√™ng bi·ªát. T·ªïng s·ªë d√≤ng = T·ªïng y√™u c·∫ßu (Total_Req).
- Ph√¢n lo·∫°i t·ª´ng d√≤ng th√†nh "B·∫Øt bu·ªôc" (Requirement) ho·∫∑c "∆Øu ti√™n" (Nice-to-have) d·ª±a tr√™n t·ª´ kh√≥a:
  * Ti·∫øng Anh: "nice to have", "plus", "preferred", "advantage", "desired", "bonus", "optional", "willing to".
  * Ti·∫øng Vi·ªát: "∆∞u ti√™n", "l·ª£i th·∫ø", "ƒëi·ªÉm c·ªông", "kh√¥ng b·∫Øt bu·ªôc", "mong mu·ªën", "n·∫øu c√≥".
  -> C√°c tr∆∞·ªùng h·ª£p c√≤n l·∫°i m·∫∑c ƒë·ªãnh l√† **"B·∫Øt bu·ªôc" (Requirement)**.
- ƒê·ªëi chi·∫øu CV: V·ªõi m·ªói d√≤ng JD, n·∫øu CV c√≥ b·∫±ng ch·ª©ng ƒë√°p ·ª©ng => T√≠nh l√† 1 ƒëi·ªÉm (Matched).
- Keyword ph√°t hi·ªán: Tr√≠ch xu·∫•t c√°c t·ª´ kh√≥a k·ªπ thu·∫≠t (Hard skill) tr√πng kh·ªõp gi·ªØa CV v√† JD.
- C√¥ng th·ª©c t√≠nh % chung: (T·ªïng s·ªë d√≤ng Matched / T·ªïng s·ªë d√≤ng JD) * 100.

B∆Ø·ªöC 3: ƒê√ÅNH GI√Å SONG NG·ªÆ (ANH & VI·ªÜT)
- T·∫°o n·ªôi dung ƒë√°nh gi√° cho c√°c m·ª•c: ƒê√°nh gi√° chung, ƒêi·ªÉm m·∫°nh, ƒêi·ªÉm y·∫øu (Missing skills), C√¢u h·ªèi ph·ªèng v·∫•n.
- N·ªôi dung Ti·∫øng Anh vi·∫øt tr∆∞·ªõc, Ti·∫øng Vi·ªát d·ªãch s√°t nghƒ©a theo sau.

B∆Ø·ªöC 4: CH·∫§M ƒêI·ªÇM RADAR (1-10) V√Ä GI·∫¢I TH√çCH L√ù DO
*B·∫Øt bu·ªôc ch·∫•m d·ª±a tr√™n Barem sau:*
1. **Hard Skills (K·ªπ nƒÉng c·ª©ng):** 1-4 (Thi·∫øu nhi·ªÅu), 5-7 (C∆° b·∫£n), 8-10 (ƒê·∫ßy ƒë·ªß/N√¢ng cao).
2. **Soft Skills (K·ªπ nƒÉng m·ªÅm):** 1-4 (S∆° s√†i), 5-7 (C√≥ nh·∫Øc ƒë·∫øn), 8-10 (C√≥ v√≠ d·ª• c·ª• th·ªÉ).
3. **Experience (Kinh nghi·ªám):** 1-4 (√çt/Tr√°i ng√†nh), 5-7 (T∆∞∆°ng ƒë·ªëi), 8-10 (V∆∞·ª£t y√™u c·∫ßu).
4. **Education (H·ªçc v·∫•n):** 1-4 (Kh√¥ng li√™n quan), 5-7 (ƒê√∫ng ng√†nh), 8-10 (B·∫±ng c·∫•p cao/Ch·ª©ng ch·ªâ x·ªãn).
5. **Domain Knowledge (Hi·ªÉu bi·∫øt ng√†nh):** 1-4 (Chung chung), 5-7 (Hi·ªÉu quy tr√¨nh), 8-10 (Am hi·ªÉu nghi·ªáp v·ª• s√¢u).

**OUTPUT FORMAT (B·∫ÆT BU·ªòC JSON):**
Ch·ªâ tr·∫£ v·ªÅ 1 JSON duy nh·∫•t.
L∆ØU √ù QUAN TR·ªåNG:
1. Kh√¥ng d√πng Markdown (```json ... ```). Tr·∫£ v·ªÅ raw text.
2. KH√îNG ƒê∆Ø·ª¢C c√≥ d·∫•u ph·∫©y (,) ·ªü cu·ªëi danh s√°ch ho·∫∑c object cu·ªëi c√πng. (NO TRAILING COMMAS).
3. ƒê·∫£m b·∫£o c·∫•u tr√∫c ngo·∫∑c {{}} ƒë√≥ng m·ªü ch√≠nh x√°c. 

C·∫•u tr√∫c nh∆∞ sau:
{{
    "personal_info": {{
        "name": "String",
        "position": "String (Single title only, e.g., 'Backend Developer')",
        "experience": "String (Single value only, e.g., '2 years')"
    }},
    "matching_score": {{
        "percentage": Integer,
        "explanation": "String (e.g., 'Matched 8/10 requirements')"
    }},
    "requirements_breakdown": {{
        "must_have_ratio": "String (e.g., '5/7')",
        "nice_to_have_ratio": "String (e.g., '3/3')"
    }},
    "matched_keywords": ["String", "String", ...],
    "radar_chart": {{
        "Hard Skills": Integer,
        "Soft Skills": Integer,
        "Experience": Integer,
        "Education": Integer,
        "Domain Knowledge": Integer
    }},
    "radar_reasoning": {{
        "Hard Skills": {{ "en": "English explanation...", "vi": "Gi·∫£i th√≠ch ti·∫øng Vi·ªát..." }},
        "Soft Skills": {{ "en": "...", "vi": "..." }},
        "Experience": {{ "en": "...", "vi": "..." }},
        "Education": {{ "en": "...", "vi": "..." }},
        "Domain Knowledge": {{ "en": "...", "vi": "..." }}
    }},
    "bilingual_content": {{
        "general_assessment": {{
            "en": "String",
            "vi": "String"
        }},
        "comparison_table": [
            {{
                "jd_requirement": "String (Original JD line)",
                "cv_evidence": "String (Evidence from CV or 'Not found')",
                "status": "Matched/Not Matched"
            }}
        ],
        "strengths": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }},
        "weaknesses_missing_skills": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }},
        "interview_questions": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }}
    }}
}}
"""

_llm_instance = None
_embedding_instance = None

def get_llm():
    global _llm_instance
    if _llm_instance is None:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print(" L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y GOOGLE_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng!")
        else:
            print(f" ƒê√£ t√¨m th·∫•y API Key: {api_key[:5]}... (·∫©n ph·∫ßn sau)")
            
        # [FIX] D√πng gemini-1.5-flash ƒë·ªÉ ·ªïn ƒë·ªãnh v√† th√¥ng minh h∆°n
        _llm_instance = ChatGoogleGenerativeAI(
            model="gemini-flash-latest", 
            temperature=0.2,
            google_api_key=api_key
        )
    return _llm_instance

def get_embeddings():
    global _embedding_instance
    if _embedding_instance is None:
        # D√πng Hugging Face (CPU) ƒë·ªÉ kh√¥ng c·∫ßn Key Google ·ªü b∆∞·ªõc n√†y
        _embedding_instance = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    return _embedding_instance

def analyze_cv_logic(file_path: str, jd_text: str):
    if not os.getenv("GOOGLE_API_KEY"):
        return {"error": "Server ch∆∞a nh·∫≠n ƒë∆∞·ª£c GOOGLE_API_KEY. H√£y ki·ªÉm tra Settings tr√™n Hugging Face."}

    # 1. X·ª≠ l√Ω PDF
    try:
        loader = PDFPlumberLoader(file_path)
        docs = loader.load()
        if not docs:
            return {"error": "Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ file PDF."}
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
    except Exception as e:
        return {"error": f"L·ªói ƒë·ªçc PDF: {str(e)}"}

    # 2. Vector Store & Chain
    try:
        embeddings = get_embeddings()
        llm = get_llm()

        # N·∫øu l·ªói x·∫£y ra ·ªü d√≤ng n√†y -> Code ch∆∞a c·∫≠p nh·∫≠t (v·∫´n d√πng Google Embeddings)
        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            collection_name=f"cv_analysis_{int(time.time())}",
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

        parser = JsonOutputParser(pydantic_object=JobMatchResult)
        prompt = ChatPromptTemplate.from_template(CORE_PROMPT)
        prompt = prompt.partial(format_instructions=parser.get_format_instructions())

        def format_docs(docs):
            return "\n\n".join(d.page_content for d in docs)

        # [FIX] ƒê·ªãnh nghƒ©a chain r√µ r√†ng h∆°n ƒë·ªÉ tr√°nh l·ªói "Missing variables"
        chain = (
            {
                "cv_text": retriever | format_docs, 
                "jd_text": RunnablePassthrough() 
            }
            | prompt
            | llm
            | parser
        )

        print("ü§ñ ƒêang ph√¢n t√≠ch v·ªõi Gemini 1.5 Flash...")
        result = chain.invoke(jd_text)
        
        vectorstore.delete_collection() 
        return result

    except Exception as e:
        # In l·ªói chi ti·∫øt ra console server ƒë·ªÉ debug
        print(f" L·ªñI PH√ÇN T√çCH: {str(e)}")
        return {"error": f"L·ªói ph√¢n t√≠ch AI: {str(e)}"}
