# backend/core_logic.py
import os
import time
from dotenv import load_dotenv
from typing import List, Dict, Union

# --- Imports ---
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_chroma import Chroma
# VáºªN DÃ™NG HUGGING FACE CHO EMBEDDINGS (Äá»ƒ trÃ¡nh lá»—i API Google khi Embedding)
from langchain_huggingface import HuggingFaceEmbeddings 
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnablePassthrough
from pydantic import BaseModel, Field

load_dotenv()

# --- DATA MODELS ---
class JobMatchResult(BaseModel):
    personal_info: Dict[str, str] = Field(description="Name, position, experience extracted from CV")
    matching_score: Dict[str, Union[int, str]] = Field(description="Percentage score and explanation")
    requirements_breakdown: Dict[str, str] = Field(description="Ratios for must-have and nice-to-have criteria")
    matched_keywords: List[str] = Field(description="List of matching technical skills")
    radar_chart: Dict[str, int] = Field(description="Scores 1-10 for 5 dimensions")
    # [NEW] ThÃªm trÆ°á»ng lÃ½ do cháº¥m Ä‘iá»ƒm
    radar_reasoning: Dict[str, Dict[str, str]] = Field(description="Reasoning in en and vi. Structure: {'Hard Skills': {'en': '...', 'vi': '...'}}")
    bilingual_content: Dict[str, Union[Dict, List]] = Field(description="Assessment content in EN and VI")

CORE_PROMPT = """
Báº¡n lÃ  má»™t Trá»£ lÃ½ Tuyá»ƒn dá»¥ng AI chuyÃªn nghiá»‡p (JobMatchr). Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phÃ¢n tÃ­ch CV (Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i dáº¡ng text) vÃ  MÃ´ táº£ cÃ´ng viá»‡c (JD - má»—i dÃ²ng lÃ  má»™t yÃªu cáº§u).

**INPUT DATA:**
1. CV Text: {cv_text}
2. JD Text: {jd_text} (LÆ°u Ã½: Má»—i dÃ²ng trong JD lÃ  má»™t tiÃªu chÃ­ riÃªng biá»‡t).

**NHIá»†M Vá»¤:**
HÃ£y thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau má»™t cÃ¡ch logic:

BÆ¯á»šC 1: TRÃCH XUáº¤T THÃ”NG TIN CÃ NHÃ‚N
- TÃ¬m Name, Position (Vá»‹ trÃ­ á»©ng tuyá»ƒn/hiá»‡n táº¡i), Experience (Tá»•ng sá»‘ nÄƒm kinh nghiá»‡m - chá»‰ láº¥y sá»‘).

BÆ¯á»šC 2: PHÃ‚N TÃCH JD VÃ€ TÃNH ÄIá»‚M (QUY Táº®C "1 Äá»€U")
- TÃ¡ch JD thÃ nh cÃ¡c dÃ²ng riÃªng biá»‡t. Tá»•ng sá»‘ dÃ²ng = Tá»•ng yÃªu cáº§u (Total_Req).
- PhÃ¢n loáº¡i tá»«ng dÃ²ng thÃ nh "Báº¯t buá»™c" (Requirement) hoáº·c "Æ¯u tiÃªn" (Nice-to-have) dá»±a trÃªn tá»« khÃ³a (náº¿u khÃ´ng rÃµ, máº·c Ä‘á»‹nh lÃ  Báº¯t buá»™c).
- Äá»‘i chiáº¿u CV: Vá»›i má»—i dÃ²ng JD, náº¿u CV cÃ³ báº±ng chá»©ng Ä‘Ã¡p á»©ng => TÃ­nh lÃ  1 Ä‘iá»ƒm (Matched).
- Keyword phÃ¡t hiá»‡n: TrÃ­ch xuáº¥t cÃ¡c tá»« khÃ³a ká»¹ thuáº­t (Hard skill) trÃ¹ng khá»›p giá»¯a CV vÃ  JD.
- CÃ´ng thá»©c tÃ­nh % chung: (Tá»•ng sá»‘ dÃ²ng Matched / Tá»•ng sá»‘ dÃ²ng JD) * 100.

BÆ¯á»šC 3: ÄÃNH GIÃ SONG NGá»® (ANH & VIá»†T)
- Táº¡o ná»™i dung Ä‘Ã¡nh giÃ¡ cho cÃ¡c má»¥c: ÄÃ¡nh giÃ¡ chung, Äiá»ƒm máº¡nh, Äiá»ƒm yáº¿u (Missing skills), CÃ¢u há»i phá»ng váº¥n.
- Ná»™i dung Tiáº¿ng Anh viáº¿t trÆ°á»›c, Tiáº¿ng Viá»‡t dá»‹ch sÃ¡t nghÄ©a theo sau.

BÆ¯á»šC 4: CHáº¤M ÄIá»‚M RADAR (1-10) VÃ€ GIáº¢I THÃCH LÃ DO
*Báº¯t buá»™c cháº¥m dá»±a trÃªn Barem sau:*
1. **Hard Skills (Ká»¹ nÄƒng cá»©ng):** 1-4 (Thiáº¿u nhiá»u), 5-7 (CÆ¡ báº£n), 8-10 (Äáº§y Ä‘á»§/NÃ¢ng cao).
2. **Soft Skills (Ká»¹ nÄƒng má»m):** 1-4 (SÆ¡ sÃ i), 5-7 (CÃ³ nháº¯c Ä‘áº¿n), 8-10 (CÃ³ vÃ­ dá»¥ cá»¥ thá»ƒ).
3. **Experience (Kinh nghiá»‡m):** 1-4 (Ãt/TrÃ¡i ngÃ nh), 5-7 (TÆ°Æ¡ng Ä‘á»‘i), 8-10 (VÆ°á»£t yÃªu cáº§u).
4. **Education (Há»c váº¥n):** 1-4 (KhÃ´ng liÃªn quan), 5-7 (ÄÃºng ngÃ nh), 8-10 (Báº±ng cáº¥p cao/Chá»©ng chá»‰ xá»‹n).
5. **Domain Knowledge (Hiá»ƒu biáº¿t ngÃ nh):** 1-4 (Chung chung), 5-7 (Hiá»ƒu quy trÃ¬nh), 8-10 (Am hiá»ƒu nghiá»‡p vá»¥ sÃ¢u).

**OUTPUT FORMAT (Báº®T BUá»˜C JSON):**
Chá»‰ tráº£ vá» 1 JSON duy nháº¥t.
LÆ¯U Ã QUAN TRá»ŒNG:
1. KhÃ´ng dÃ¹ng Markdown (```json ... ```). Tráº£ vá» raw text.
2. KHÃ”NG ÄÆ¯á»¢C cÃ³ dáº¥u pháº©y (,) á»Ÿ cuá»‘i danh sÃ¡ch hoáº·c object cuá»‘i cÃ¹ng. (NO TRAILING COMMAS).
3. Äáº£m báº£o cáº¥u trÃºc ngoáº·c {{}} Ä‘Ã³ng má»Ÿ chÃ­nh xÃ¡c. 

Cáº¥u trÃºc nhÆ° sau:
{{
    "personal_info": {{
        "name": "String",
        "position": "String (Single title only, e.g., 'Backend Developer')",
        "experience": "String (Single value only, e.g., '2 years')"
    }},
    "matching_score": {{
        "percentage": Integer,
        "explanation": "String (e.g., 'Matched 8/10 requirements')"
    }},
    "requirements_breakdown": {{
        "must_have_ratio": "String (e.g., '5/7')",
        "nice_to_have_ratio": "String (e.g., '3/3')"
    }},
    "matched_keywords": ["String", "String", ...],
    "radar_chart": {{
        "Hard Skills": Integer,
        "Soft Skills": Integer,
        "Experience": Integer,
        "Education": Integer,
        "Domain Knowledge": Integer
    }},
    "radar_reasoning": {{
        "Hard Skills": {{ "en": "English explanation...", "vi": "Giáº£i thÃ­ch tiáº¿ng Viá»‡t..." }},
        "Soft Skills": {{ "en": "...", "vi": "..." }},
        "Experience": {{ "en": "...", "vi": "..." }},
        "Education": {{ "en": "...", "vi": "..." }},
        "Domain Knowledge": {{ "en": "...", "vi": "..." }}
    }},
    "bilingual_content": {{
        "general_assessment": {{
            "en": "String",
            "vi": "String"
        }},
        "comparison_table": [
            {{
                "jd_requirement": "String (Original JD line)",
                "cv_evidence": "String (Evidence from CV or 'Not found')",
                "status": "Matched/Not Matched"
            }}
        ],
        "strengths": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }},
        "weaknesses_missing_skills": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }},
        "interview_questions": {{
            "en": ["String", "String"],
            "vi": ["String", "String"]
        }}
    }}
}}
"""

_llm_instance = None
_embedding_instance = None

def get_llm():
    global _llm_instance
    if _llm_instance is None:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âŒ Lá»–I NGHIÃŠM TRá»ŒNG: KhÃ´ng tÃ¬m tháº¥y GOOGLE_API_KEY trong biáº¿n mÃ´i trÆ°á»ng!")
        else:
            print(f"âœ… ÄÃ£ tÃ¬m tháº¥y API Key: {api_key[:5]}... (áº©n pháº§n sau)")
            
        # [FIX] DÃ¹ng gemini-1.5-flash Ä‘á»ƒ á»•n Ä‘á»‹nh vÃ  thÃ´ng minh hÆ¡n
        _llm_instance = ChatGoogleGenerativeAI(
            model="gemini-flash-latest", 
            temperature=0.2,
            google_api_key=api_key
        )
    return _llm_instance

def get_embeddings():
    global _embedding_instance
    if _embedding_instance is None:
        # DÃ¹ng Hugging Face (CPU) Ä‘á»ƒ khÃ´ng cáº§n Key Google á»Ÿ bÆ°á»›c nÃ y
        _embedding_instance = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    return _embedding_instance

def analyze_cv_logic(file_path: str, jd_text: str):
    if not os.getenv("GOOGLE_API_KEY"):
        return {"error": "Server chÆ°a nháº­n Ä‘Æ°á»£c GOOGLE_API_KEY. HÃ£y kiá»ƒm tra Settings trÃªn Hugging Face."}

    # 1. Xá»­ lÃ½ PDF
    try:
        loader = PDFPlumberLoader(file_path)
        docs = loader.load()
        if not docs:
            return {"error": "KhÃ´ng thá»ƒ Ä‘á»c ná»™i dung tá»« file PDF."}
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
    except Exception as e:
        return {"error": f"Lá»—i Ä‘á»c PDF: {str(e)}"}

    # 2. Vector Store & Chain
    try:
        embeddings = get_embeddings()
        llm = get_llm()

        # Náº¿u lá»—i xáº£y ra á»Ÿ dÃ²ng nÃ y -> Code chÆ°a cáº­p nháº­t (váº«n dÃ¹ng Google Embeddings)
        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            collection_name=f"cv_analysis_{int(time.time())}",
        )
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

        parser = JsonOutputParser(pydantic_object=JobMatchResult)
        prompt = ChatPromptTemplate.from_template(CORE_PROMPT)
        prompt = prompt.partial(format_instructions=parser.get_format_instructions())

        def format_docs(docs):
            return "\n\n".join(d.page_content for d in docs)

        # [FIX] Äá»‹nh nghÄ©a chain rÃµ rÃ ng hÆ¡n Ä‘á»ƒ trÃ¡nh lá»—i "Missing variables"
        chain = (
            {
                "cv_text": retriever | format_docs, 
                "jd_text": RunnablePassthrough() 
            }
            | prompt
            | llm
            | parser
        )

        print("ğŸ¤– Äang phÃ¢n tÃ­ch vá»›i Gemini 1.5 Flash...")
        result = chain.invoke(jd_text)
        
        vectorstore.delete_collection() 
        return result

    except Exception as e:
        # In lá»—i chi tiáº¿t ra console server Ä‘á»ƒ debug
        print(f"âŒ Lá»–I PHÃ‚N TÃCH: {str(e)}")
        return {"error": f"Lá»—i phÃ¢n tÃ­ch AI: {str(e)}"}
